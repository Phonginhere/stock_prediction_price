{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "363d4aee-6cf3-4c1b-bff7-fe87dc135b09",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1731474852400,
    "lastExecutedByKernel": "b758ff07-d9e6-42ac-a379-9fac2235c78a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import os\nimport pandas as pd\nimport yfinance as yf\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5254df9-0605-495d-b8f4-795c1bf06d79",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 56,
    "lastExecutedAt": 1731474852456,
    "lastExecutedByKernel": "b758ff07-d9e6-42ac-a379-9fac2235c78a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def load_process_data(ticker, start_date, end_date, dealNaN=True, drop_NaN=True, split_by_ratio=True, split_by_date=False, split_by_randomly=False, split_date=None, scale=True):\n    DATA_DIR = 'stock_data'\n    \n    test_size = 0.2\n    feature_columns = [\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\"]\n    \n    # Check if the data directory exists, if not, create it\n    if not os.path.exists(DATA_DIR):\n        os.makedirs(DATA_DIR)\n    \n    # Create a file path for the stock data\n    file_path = os.path.join(DATA_DIR, f'{ticker}_{start_date}_{end_date}.csv')\n    \n    # Load or download data\n    if os.path.exists(file_path):\n        print(f\"Loading data from {file_path}\")\n        data = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n    else:\n        print(f\"Downloading data for {ticker} from Yahoo finance\")\n        data = yf.download(ticker, start=start_date, end=end_date)\n        data.to_csv(file_path)\n        print(f\"Data saved to {file_path}\")\n    \n    result = {'data': data.copy()}\n    \n    # Handle NaN values\n    if dealNaN:\n        # Check for NaN values before handling\n        print(\"NaN values before handling\")\n        print(data.isna().sum())\n        # Depends on chosen drop or fill NaN\n        if drop_NaN is True:\n            data.dropna(inplace=True)\n        else:\n            data.fillna(data.mean(), inplace=True)\n        # Check for NaN values after handling\n        print(\"NaN values after handling\")\n        print(data.isna().sum())\n    \n    # Split data with specified method\n    if split_by_ratio:\n        print('Splitting by ratio')\n        train_samples = int((1-test_size) * len(data))\n        \n        result['data_train'] = data[:train_samples]\n        result['data_test'] = data[train_samples:]\n        \n        print(f\"Training samples: {len(result['data_train'])}\")\n        print(f\"Training samples: {len(result['data_test'])}\")\n        \n    elif split_by_date and split_date is not None:\n        print('Splitting by date')\n        split_date = pd.to_datetime(split_date)\n        \n        result['data_train'] = data[data.index <= split_date]\n        result['data_test'] = data[data.index > split_date]\n        \n        print(f\"Training samples: {len(result['data_train'])}\")\n        print(f\"Training samples: {len(result['data_test'])}\")\n    elif split_by_randomly:\n        print('Randomly splitting with shuffling')\n        result['data_train'], result['data_test'] = train_test_split(data, test_size=test_size, shuffle=True)\n        \n        print(f\"Training samples: {len(result['data_train'])}\")\n        print(f\"Training samples: {len(result['data_test'])}\")\n    \n    # Optionally scale feature columns\n    if scale:\n        scaler = MinMaxScaler(feature_range=(0,1))\n        data[feature_columns] = scaler.fit_transform(data[feature_columns])\n        result['scaled_data'] = data[feature_columns]\n        \n    return result"
   },
   "outputs": [],
   "source": [
    "def load_process_data(ticker, start_date, end_date, dealNaN=True, drop_NaN=True, split_by_ratio=True, split_by_date=False, split_by_randomly=False, split_date=None, scale=True):\n",
    "    DATA_DIR = 'stock_data'\n",
    "    \n",
    "    test_size = 0.2\n",
    "    feature_columns = [\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\"]\n",
    "    \n",
    "    # Check if the data directory exists, if not, create it\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        os.makedirs(DATA_DIR)\n",
    "    \n",
    "    # Create a file path for the stock data\n",
    "    file_path = os.path.join(DATA_DIR, f'{ticker}_{start_date}_{end_date}.csv')\n",
    "    \n",
    "    # Load or download data\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading data from {file_path}\")\n",
    "        data = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "    else:\n",
    "        print(f\"Downloading data for {ticker} from Yahoo finance\")\n",
    "        data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        data.to_csv(file_path)\n",
    "        print(f\"Data saved to {file_path}\")\n",
    "    \n",
    "    result = {'data': data.copy()}\n",
    "    \n",
    "    # Handle NaN values\n",
    "    if dealNaN:\n",
    "        # Check for NaN values before handling\n",
    "        print(\"NaN values before handling\")\n",
    "        print(data.isna().sum())\n",
    "        # Depends on chosen drop or fill NaN\n",
    "        if drop_NaN is True:\n",
    "            data.dropna(inplace=True)\n",
    "        else:\n",
    "            data.fillna(data.mean(), inplace=True)\n",
    "        # Check for NaN values after handling\n",
    "        print(\"NaN values after handling\")\n",
    "        print(data.isna().sum())\n",
    "    \n",
    "    # Split data with specified method\n",
    "    if split_by_ratio:\n",
    "        print('Splitting by ratio')\n",
    "        train_samples = int((1-test_size) * len(data))\n",
    "        \n",
    "        result['data_train'] = data[:train_samples]\n",
    "        result['data_test'] = data[train_samples:]\n",
    "        \n",
    "        print(f\"Training samples: {len(result['data_train'])}\")\n",
    "        print(f\"Test samples: {len(result['data_test'])}\")\n",
    "        \n",
    "    elif split_by_date and split_date is not None:\n",
    "        print('Splitting by date')\n",
    "        split_date = pd.to_datetime(split_date)\n",
    "        \n",
    "        result['data_train'] = data[data.index <= split_date]\n",
    "        result['data_test'] = data[data.index > split_date]\n",
    "        \n",
    "        print(f\"Training samples: {len(result['data_train'])}\")\n",
    "        print(f\"Test samples: {len(result['data_test'])}\")\n",
    "    elif split_by_randomly:\n",
    "        print('Randomly splitting with shuffling')\n",
    "        result['data_train'], result['data_test'] = train_test_split(data, test_size=test_size, shuffle=True)\n",
    "        \n",
    "        print(f\"Training samples: {len(result['data_train'])}\")\n",
    "        print(f\"Test samples: {len(result['data_test'])}\")\n",
    "    \n",
    "    # Optionally scale feature columns\n",
    "    if scale:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        data[feature_columns] = scaler.fit_transform(data[feature_columns])\n",
    "        result['scaled_data'] = data[feature_columns]\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3ac8c78-559f-40c7-889e-59b49ba1d2e4",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 102,
    "lastExecutedAt": 1731474852558,
    "lastExecutedByKernel": "b758ff07-d9e6-42ac-a379-9fac2235c78a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "TICKER = 'AAPL'\nSTART_DATE = '2020-01-01'\nEND_DATE = '2023-01-01'\n\nresult = load_process_data(ticker=TICKER, start_date=START_DATE, end_date=END_DATE, split_by_date=False, split_by_randomly=False, split_by_ratio=True, split_date='06-01-2021', scale=True)\n\nprint(\"Train data in first 5 rows\")\nprint(result['data_train'].head())\nprint(\"Test data in first 5 rows\")\nprint(result['data_test'].head())",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     },
     "1": {
      "height": 616,
      "type": "stream"
     },
     "2": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for AAPL from Yahoo finance\n",
      "Data saved to stock_data/AAPL_2020-01-01_2023-01-01.csv\n",
      "NaN values before handling\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "NaN values after handling\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "Splitting by ratio\n",
      "Training samples: 604\n",
      "Training samples: 152\n",
      "Train data in first 5 rows\n",
      "                 Open       High        Low      Close  Adj Close     Volume\n",
      "Date                                                                        \n",
      "2020-01-02  74.059998  75.150002  73.797501  75.087502  72.796028  135480400\n",
      "2020-01-03  74.287498  75.144997  74.125000  74.357498  72.088287  146322800\n",
      "2020-01-06  73.447502  74.989998  73.187500  74.949997  72.662704  118387200\n",
      "2020-01-07  74.959999  75.224998  74.370003  74.597504  72.320969  108872000\n",
      "2020-01-08  74.290001  76.110001  74.290001  75.797501  73.484344  132079200\n",
      "Test data in first 5 rows\n",
      "                  Open        High  ...   Adj Close     Volume\n",
      "Date                                ...                       \n",
      "2022-05-25  138.429993  141.789993  ...  138.634857   92482700\n",
      "2022-05-26  137.389999  144.339996  ...  141.851059   90601500\n",
      "2022-05-27  145.389999  149.679993  ...  147.632462   90978500\n",
      "2022-05-31  149.070007  150.660004  ...  146.843170  103718400\n",
      "2022-06-01  149.899994  151.740005  ...  146.714920   74286600\n",
      "\n",
      "[5 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TICKER = 'AAPL'\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2023-01-01'\n",
    "\n",
    "result = load_process_data(ticker=TICKER, start_date=START_DATE, end_date=END_DATE, split_by_date=False, split_by_randomly=False, split_by_ratio=True, split_date='06-01-2021', scale=True)\n",
    "\n",
    "print(\"Train data in first 5 rows\")\n",
    "print(result['data_train'].head())\n",
    "print(\"Test data in first 5 rows\")\n",
    "print(result['data_test'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad51a097-8f23-4abd-b9e5-74c6094fd8f3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1731474852612,
    "lastExecutedByKernel": "b758ff07-d9e6-42ac-a379-9fac2235c78a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "result = load_process_data(ticker=TICKER, start_date=START_DATE, end_date=END_DATE, split_by_date=True, split_by_randomly=False, split_by_ratio=False, split_date='06-01-2021', scale=True)",
    "outputsMetadata": {
     "0": {
      "height": 437,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from stock_data/AAPL_2020-01-01_2023-01-01.csv\n",
      "NaN values before handling\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "NaN values after handling\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "Splitting by date\n",
      "Training samples: 356\n",
      "Training samples: 400\n"
     ]
    }
   ],
   "source": [
    "result = load_process_data(ticker=TICKER, start_date=START_DATE, end_date=END_DATE, split_by_date=True, split_by_randomly=False, split_by_ratio=False, split_date='06-01-2021', scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9df7b8b-480a-44c8-976d-0be9b6c7daf0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1731474852664,
    "lastExecutedByKernel": "b758ff07-d9e6-42ac-a379-9fac2235c78a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "result = load_process_data(ticker=TICKER, start_date=START_DATE, end_date=END_DATE, split_by_date=False, split_by_randomly=True, split_by_ratio=False, split_date='06-01-2021', scale=True)\n\nprint(\"Train data in first 5 rows\")\nprint(result['data_train'].head())\nprint(\"Test data in first 5 rows\")\nprint(result['data_test'].head())",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from stock_data/AAPL_2020-01-01_2023-01-01.csv\n",
      "NaN values before handling\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "NaN values after handling\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "Randomly splitting with shuffling\n",
      "Training samples: 604\n",
      "Training samples: 152\n",
      "Train data in first 5 rows\n",
      "                  Open        High  ...   Adj Close     Volume\n",
      "Date                                ...                       \n",
      "2022-04-07  171.160004  173.360001  ...  169.581436   77594700\n",
      "2022-01-28  165.710007  170.350006  ...  167.584839  179935700\n",
      "2021-03-05  120.980003  121.940002  ...  118.908562  153766600\n",
      "2021-07-19  143.750000  144.070007  ...  139.740540  121434600\n",
      "2022-10-07  142.539993  143.100006  ...  138.402542   85925600\n",
      "\n",
      "[5 rows x 6 columns]\n",
      "Test data in first 5 rows\n",
      "                  Open        High  ...   Adj Close     Volume\n",
      "Date                                ...                       \n",
      "2020-02-14   81.184998   81.495003  ...   78.945251   80113600\n",
      "2020-08-06  110.404999  114.412498  ...  110.988197  202428800\n",
      "2022-05-04  159.669998  166.479996  ...  163.552444  108256500\n",
      "2020-11-13  119.440002  119.669998  ...  116.618988   81581900\n",
      "2022-04-18  163.919998  166.600006  ...  162.616547   69023900\n",
      "\n",
      "[5 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "result = load_process_data(ticker=TICKER, start_date=START_DATE, end_date=END_DATE, split_by_date=False, split_by_randomly=True, split_by_ratio=False, split_date='06-01-2021', scale=True)\n",
    "\n",
    "print(\"Train data in first 5 rows\")\n",
    "print(result['data_train'].head())\n",
    "print(\"Test data in first 5 rows\")\n",
    "print(result['data_test'].head())"
   ]
  }
 ],
 "metadata": {
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
